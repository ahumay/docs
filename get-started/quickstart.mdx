---
title: 'Quickstart'
description: 'Get started with the TAMC Super Model Router API.'
---

### API Access

**Invitation-Only Access:**  
Access to the TAMC Super Model Router API is granted on an invitation-only basis. If you have been invited, you should have received your API credentials. The API is available at:

```
https://api.americanmodel.co/v1
```

### Authentication

All API requests require authentication using your API key in the Authorization header:

```
Authorization: Bearer YOUR_API_KEY
```

### API Endpoints

#### Chat Completions

The TAMC Super Model Router will automatically select the best model for your query. You can either let the router choose the optimal model or specify a list of preferred models.

```http
POST /v1/chat/completions
Content-Type: application/json
Authorization: Bearer YOUR_API_KEY

{
  "messages": [
    {
      "role": "user",
      "content": "Write merge sort in 3 lines."
    }
  ]
}
```

Or with specific models:

```http
POST /v1/chat/completions
Content-Type: application/json
Authorization: Bearer YOUR_API_KEY

{
  "messages": [
    {
      "role": "user",
      "content": "Write merge sort in 3 lines."
    }
  ],
  "model": [
    "{model1}",
    "{model2}"
  ]
}
```

Response:
```json
{
  "result": {
    "content": "def merge_sort(arr):\n    if len(arr) <= 1: return arr\n    mid = len(arr) // 2\n    return merge(merge_sort(arr[:mid]), merge_sort(arr[mid:]))"
  },
  "session_id": "session_123",
  "selected_provider": {
    "model": "model1"
  }
}
```

### Client Examples

#### Python Example

```python
import requests

API_KEY = "YOUR_API_KEY"
API_URL = "https://api.americanmodel.co/v1"

# Define your query message
messages = [
  {"role": "user", "content": "Write merge sort in 3 lines."}
]

# Option 1: Let the router choose the best model
response = requests.post(
    f"{API_URL}/chat/completions",
    headers={
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    },
    json={
        "messages": messages
    }
)

# Option 2: Specify preferred models
llm_providers = [
  "{model1}",
  "{model2}"
]
response = requests.post(
    f"{API_URL}/chat/completions",
    headers={
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    },
    json={
        "messages": messages,
        "model": llm_providers
    }
)

result = response.json()
print("Session ID:", result["session_id"])
print("Selected LLM:", result["selected_provider"]["model"])
print("Response:", result["result"]["content"])
```

#### TypeScript/Node.js Example

```typescript
const axios = require("axios");

const API_KEY = "YOUR_API_KEY";
const API_URL = "https://api.americanmodel.co/v1";

const messages = [
  { role: "user", content: "Explain how quantum genomics works." }
];

// Option 1: Let the router choose the best model
axios.post(
    `${API_URL}/chat/completions`,
    { messages },
    {
        headers: {
            Authorization: `Bearer ${API_KEY}`,
            "Content-Type": "application/json"
        }
    }
)
.then(({ data }) => {
    console.log("Session ID:", data.session_id);
    console.log("Selected LLM:", data.selected_provider.model);
    console.log("Response:", data.result.content);
})
.catch(error => {
    console.error("Error:", error.response?.data || error.message);
});

// Option 2: Specify preferred models
const llmProviders = [
    "{model1}",
    "{model2}"
];

axios.post(
    `${API_URL}/chat/completions`,
    {
        messages,
        model: llmProviders
    },
    {
        headers: {
            Authorization: `Bearer ${API_KEY}`,
            "Content-Type": "application/json"
        }
    }
)
.then(({ data }) => {
    console.log("Session ID:", data.session_id);
    console.log("Selected LLM:", data.selected_provider.model);
    console.log("Response:", data.result.content);
})
.catch(error => {
    console.error("Error:", error.response?.data || error.message);
});
```

## Conclusion

The TAMC Super Model Router API allows you to seamlessly integrate multiple LLMs into your application without the overhead of custom training. This managed service ensures that each query is handled by the best available model, either automatically selected by our router or from your preferred list. For additional details, please contact our support team at [ahumay@americanmodel.co](mailto:ahumay@americanmodel.co).
